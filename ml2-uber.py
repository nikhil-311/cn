# -*- coding: utf-8 -*-
"""ML2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yo8F-gLA9DgyMYRNBS-OijaINRzd8WiI
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler


df=pd.read_csv(r"C:\Users\Acer\Desktop\dmv and ml\ML\DATASETS\uber.csv")


df


df.head()


df.tail(8)


df.info()


df.columns


df.drop(['Unnamed: 0', 'key'], axis=1, inplace=True)


df.head()


df.info()


# Drop rows with missing values
df= df.dropna()


df


# Identify outliers using box plots
df.plot(kind = "box",subplots = True,layout = (6,2),figsize = (15,20))
plt.show()


features = df[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count']]
plt.figure(figsize =(10,6))
sns.boxplot(data = features)
plt.show()


# Define a function to remove outliers using the IQR method
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
# Apply the function to the dataset
# You may choose relevant columns for outlier removal
columns_to_check = ['fare_amount', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count']
data_cleaned = df.copy()
for column in columns_to_check:
    data_cleaned = remove_outliers(data_cleaned, column)
# Check the shape of the dataset before and after outlier removal
print("Original dataset shape:", df.shape)
print("Cleaned dataset shape:", data_cleaned.shape)


features1 = data_cleaned[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count']]
target = data_cleaned['fare_amount']


# Identify outliers using box plots if reamining
plt.figure(figsize=(10, 6))
sns.boxplot(data=features1)
plt.show()


# Check for non-numeric columns
non_numeric_cols = data_cleaned.select_dtypes(exclude=[np.number]).columns
print("Non-numeric columns to be handled:", non_numeric_cols)
# Drop non-numeric columns for correlation calculation
data_numeric = data_cleaned.select_dtypes(include=[np.number])
# Correlation matrix
correlation_matrix = data_numeric.corr()
plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True)
plt.show()


# Check for missing values
df.isnull().sum()
# Drop rows with missing values
df.dropna(inplace=True)
# Drop duplicate entries if any
df.drop_duplicates(inplace=True)


# Filter valid coordinates
df = df[
     (df['pickup_latitude'].between(-90, 90)) &
     (df['dropoff_latitude'].between(-90, 90)) &
     (df['pickup_longitude'].between(-180, 180)) &
     (df['dropoff_longitude'].between(-180, 180))
]


from geopy.distance import geodesic
def calculate_distance(row):
    pickup = (row['pickup_latitude'], row['pickup_longitude'])
    dropoff = (row['dropoff_latitude'], row['dropoff_longitude'])
    return geodesic(pickup, dropoff).km
df['distance_km'] = df.apply(calculate_distance, axis=1)


#Remove fares <= 0 or very large (outliers):
df = df[(df['fare_amount'] > 0) & (df['fare_amount'] < 100)]
df = df[df['distance_km'] < 100]


#Extract useful features:
df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])
df['hour'] = df['pickup_datetime'].dt.hour
df['day'] = df['pickup_datetime'].dt.dayofweek
df['month'] = df['pickup_datetime'].dt.month


df


plt.figure(figsize=(10,6))
sns.heatmap(df[['fare_amount', 'distance_km', 'hour', 'day', 'month']].corr(), annot=True)
plt.title('Correlation Matrix')
plt.show()


#prepare data for modeling
features = ['distance_km', 'hour', 'day', 'month']
X = df[features]
y = df['fare_amount']
# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)


#Train Models
#Linear Regression
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)


#Ridge regression
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)
y_pred_ridge = ridge.predict(X_test)


#Lasso Regression
lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)
y_pred_lasso = lasso.predict(X_test)


#7. Evaluate Models
#Choose the best model based on lowest RMSE and highest RÂ².
def evaluate_model(y_test, y_pred, model_name):
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    print(f"{model_name}:\nRMSE: {rmse:.2f}, R2 Score: {r2:.4f}\n")
evaluate_model(y_test, y_pred_lr, 'Linear Regression')
evaluate_model(y_test, y_pred_ridge, 'Ridge Regression')
evaluate_model(y_test, y_pred_lasso, 'Lasso Regression')


plt.figure(figsize=(8,6))
plt.scatter(y_test, y_pred_lr, alpha=0.3, label='Linear Regression')
plt.xlabel("Actual Fare")
plt.ylabel("Predicted Fare")
plt.title("Actual vs Predicted Fare Amount")
plt.legend()
plt.grid(True)
plt.show()

